{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "reddit_data = pd.read_csv('Final_formatted_data.csv')\n",
    "reddit_data.head()\n",
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing varied Scikit-learn ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing model keeping Title as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reddit_data['title'] #Dependent variable\n",
    "y = reddit_data['flair'] #Independent variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy 0.475\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.79      0.92      0.85        12\n",
      "     Non-Political       0.45      0.31      0.37        16\n",
      "     [R]eddiquette       0.33      0.38      0.35         8\n",
      "         Scheduled       0.62      0.31      0.42        16\n",
      "       Photography       0.27      0.33      0.30         9\n",
      "Science/Technology       0.78      0.78      0.78         9\n",
      "          Politics       0.18      0.25      0.21         8\n",
      "  Business/Finance       0.06      0.17      0.09         6\n",
      "    Policy/Economy       0.91      1.00      0.95        10\n",
      "            Sports       0.57      0.44      0.50         9\n",
      "              Food       0.62      0.71      0.67         7\n",
      "               AMA       0.20      0.10      0.13        10\n",
      "\n",
      "          accuracy                           0.48       120\n",
      "         macro avg       0.48      0.48      0.47       120\n",
      "      weighted avg       0.51      0.47      0.48       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayse Classifier\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "NB = nb.fit(X_train, y_train)\n",
    "#pickle.dump(NB,open(\"model_NB.sav\",'wb'))\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"NB accuracy {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD accuracy 0.4583333333333333\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.80      1.00      0.89        12\n",
      "     Non-Political       0.45      0.31      0.37        16\n",
      "     [R]eddiquette       0.17      0.12      0.14         8\n",
      "         Scheduled       0.54      0.44      0.48        16\n",
      "       Photography       0.33      0.33      0.33         9\n",
      "Science/Technology       0.47      0.78      0.58         9\n",
      "          Politics       0.17      0.25      0.20         8\n",
      "  Business/Finance       0.00      0.00      0.00         6\n",
      "    Policy/Economy       0.83      1.00      0.91        10\n",
      "            Sports       0.44      0.44      0.44         9\n",
      "              Food       0.80      0.57      0.67         7\n",
      "               AMA       0.00      0.00      0.00        10\n",
      "\n",
      "          accuracy                           0.46       120\n",
      "         macro avg       0.42      0.44      0.42       120\n",
      "      weighted avg       0.44      0.46      0.44       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "SGD = sgd.fit(X_train, y_train)\n",
    "#pickle.dump(SGD,open(\"model_SGC.sav\",'wb'))\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(f\"SGD accuracy {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG accuracy % 0.475\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.92      0.92      0.92        12\n",
      "     Non-Political       0.46      0.38      0.41        16\n",
      "     [R]eddiquette       0.25      0.25      0.25         8\n",
      "         Scheduled       0.67      0.50      0.57        16\n",
      "       Photography       0.30      0.33      0.32         9\n",
      "Science/Technology       0.50      0.67      0.57         9\n",
      "          Politics       0.15      0.25      0.19         8\n",
      "  Business/Finance       0.00      0.00      0.00         6\n",
      "    Policy/Economy       0.91      1.00      0.95        10\n",
      "            Sports       0.50      0.56      0.53         9\n",
      "              Food       0.50      0.57      0.53         7\n",
      "               AMA       0.00      0.00      0.00        10\n",
      "\n",
      "          accuracy                           0.48       120\n",
      "         macro avg       0.43      0.45      0.44       120\n",
      "      weighted avg       0.47      0.47      0.47       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshitaggarwal/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshitaggarwal/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "LOGREG = logreg.fit(X_train, y_train)\n",
    "#pickle.dump(LOGREG,open(\"model_LOGREG.sav\",'wb'))\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(f\"LOG accuracy {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "f37af5b1-c3b4-4d3e-961b-f97293be30a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
